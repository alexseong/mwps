{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os, re\n",
    "import sys, random\n",
    "import yaml, time\n",
    "import json\n",
    "import pickle\n",
    "from word2number import w2n\n",
    "from EquationConverter import EquationConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = os.path.join(os.getcwd(), '../MWP-Automatic-Solver/data')\n",
    "data_dir = os.path.join(data_root_dir, 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_LIST = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/DL/MWPS/mwps'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIR_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "DIR_PATH = os.path.abspath(os.getcwd())\n",
    "DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GENERATED = False\n",
    "TEST_SPLIT = 0.05\n",
    "WORDS_FOR_OPERATORS = False\n",
    "\n",
    "# Composite list of MWPs\n",
    "PROBLEM_LIST = []\n",
    "\n",
    "# The same list with all equations converted from infix to cleaned infix\n",
    "CLEAN_INFIX_CONVERTED_PROBLEM_LIST = []\n",
    "\n",
    "# The same list with all equations converted from infix to Polish notation\n",
    "POLISH_CONVERTED_PROBLEM_LIST = []\n",
    "\n",
    "# The same list with all equations converted from infix to Reverse Polish notation\n",
    "REVERSE_POLISH_CONVERTED_PROBLEM_LIST = []\n",
    "\n",
    "# The generated data (not used in testing)\n",
    "GENERATED = []\n",
    "\n",
    "# Dataset specific\n",
    "AI2 = []\n",
    "ILLINOIS = []\n",
    "COMMONCORE = []\n",
    "MAWPS = []\n",
    "\n",
    "KEEP_INFIX_PARENTHESIS = True\n",
    "MAKE_IND_SETS = True\n",
    "\n",
    "# Large test sets\n",
    "PREFIX_TEST = []\n",
    "POSTFIX_TEST = []\n",
    "INFIX_TEST = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "'dataset': 'train_all_postfix.p',\n",
    "'duplication': False,\n",
    "'test': 'postfix',\n",
    "'model': False,\n",
    "'layers': 2,\n",
    "'heads': 8,\n",
    "'d_model': 256,\n",
    "'dff': 1024,\n",
    "'lr': 'scheduled',\n",
    "'dropout': 0.1,\n",
    "'epochs': 300,\n",
    "'batch': 128,\n",
    "'pretrain': False,\n",
    "'beta_1': 0.95,\n",
    "'beta_2': 0.99,\n",
    "'pos': False,\n",
    "'pos_words': False,\n",
    "'remove_stopwords': False,\n",
    "'as_lemmas': False,\n",
    "'reorder': False,\n",
    "'tagging': 'lst',\n",
    "'input': False,\n",
    "'seed': 420365,\n",
    "'save': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = settings['seed']\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sentence_clean(text):\n",
    "    # Clean up the data and separate everything by spaces\n",
    "    text = re.sub(r\"(?<!Mr|Mr|Dr|Ms)(?<!Mrs)(?<![0-9])(\\s+)?\\.(\\s+)?\", \" . \",\n",
    "                  text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"(\\s+)?\\?(\\s+)?\", \" ? \", text)\n",
    "    text = re.sub(r\",\", \"\", text)\n",
    "    text = re.sub(r\"^\\s+\", \"\", text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace(\"'\", \" '\")\n",
    "    text = text.replace('%', ' percent')\n",
    "    text = text.replace('$', ' $ ')\n",
    "    text = re.sub(r\"\\.\\s+\", \" . \", text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    \n",
    "    sent = []\n",
    "    for word in text.split(' '):\n",
    "        try:\n",
    "            sent.append(str(w2n.word_to_num(word)))\n",
    "        except:\n",
    "            sent.append(word)\n",
    "    \n",
    "    return ' '.join(sent)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_case(text):\n",
    "    try:\n",
    "        return text.lower()\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_AI2():\n",
    "    print(\"\\nWorking on AI2 data...\")\n",
    "    problem_list = []\n",
    "    with open(os.path.join(data_dir, 'AI2/questions.txt'), \"r\") as fh:\n",
    "        content = fh.readlines()\n",
    "        \n",
    "    for i in range(len(content)):\n",
    "        if i % 3 ==0 or i == 0:\n",
    "            question_text = one_sentence_clean(content[i].strip())            \n",
    "            eq = content[i + 2].strip()\n",
    "            \n",
    "            problem = [(\"question\", to_lower_case(question_text)),\n",
    "                       (\"equation\", to_lower_case(eq)),\n",
    "                       (\"answer\", content[i+1].strip())\n",
    "                      ]\n",
    "            \n",
    "            if problem != []:\n",
    "                problem_list.append(problem)\n",
    "                AI2.append(problem)\n",
    "        \n",
    "    total_problems = int(len(content) / 3)    \n",
    "    print(f\"-> Retrived {len(problem_list)} / {total_problems} problems.\")\n",
    "    print(\"...done.\\n\")\n",
    "            \n",
    "    return AI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_all_datasets():\n",
    "    total_datasets = []\n",
    "    # Iteratively rework all the data\n",
    "    total_datasets.append(transform_AI2())\n",
    "#     total_datasets.append(transform_CommonCore())\n",
    "#     total_datasets.append(transform_Illinois())\n",
    "#     total_datasets.append(transform_MaWPS())\n",
    "#     if USE_GENERATED:\n",
    "#         total_datasets.append(transform_custom())\n",
    "\n",
    "    return total_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to(problem_list, tag):\n",
    "    output = []\n",
    "    \n",
    "    for problem in problem_list:\n",
    "        problem_dict = dict(problem)\n",
    "        ol = []\n",
    "        discard = False\n",
    "        \n",
    "        for k, v in problem_dict.items():\n",
    "            if k == 'equation':\n",
    "                convert = EquationConverter()\n",
    "                convert.eqset(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming all original datasets...\n",
      "Splitting 95.0% for training.\n",
      "NOTE: Find resulting data binaries in the data folder.\n",
      "\n",
      "Working on AI2 data...\n",
      "-> Retrived 395 / 395 problems.\n",
      "...done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming all original datasets...\")\n",
    "print(f\"Splitting {(1 - TEST_SPLIT) * 100}% for training.\")\n",
    "print(\"NOTE: Find resulting data binaries in the data folder.\")\n",
    "total_filtered_datasets = transform_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "AI2_TEST = AI2[:int(len(AI2) * TEST_SPLIT)]\n",
    "AI2 = AI2[int(len(AI2) * TEST_SPLIT):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_LIST += AI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('question',\n",
       "  'joan has 9 blue balloons sally has 5 blue balloons and jessica has 2 blue balloons . how many blue balloons do they have in total ? '),\n",
       " ('equation', 'x = 9 + 5 + 2'),\n",
       " ('answer', '16')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(PROBLEM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0c597ecd9ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pre_ai2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAI2_TEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prefix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_to' is not defined"
     ]
    }
   ],
   "source": [
    "test_pre_ai2 = convert_to(AI2_TEST, \"prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x ='"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation = AI2[0][1][1]\n",
    "eq = re.search(r\"([a-z]+(\\s+)?=|=(\\s+)?[a-z]+)\", equation).group(1)\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x '"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = re.sub(\"=\", \"\", eq)\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = re.sub(r\"([a-z]+(\\s+)?=|=(\\s+)?[a-z]+)\", \"\", eq)\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x=9+5+2', 'x')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation.replace(' ', \"\"), eq.replace(' ', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', '=', '9', '+', '5', '+', '2']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_expression = re.findall(r\"(\\d*\\.?\\d+|[^0-9])\", equation.replace(' ', \"\"))\n",
    "split_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATORS = {'+', '-', '*', '/', '(', ')', '^'}\n",
    "PRIORITY = {'+': 2, '-': 2, '*': 3, '/': 3, '^': 4}\n",
    "\n",
    "def __infix_to_postfix(filtered_expresseion, equation_equals):\n",
    "        stack = []\n",
    "        output = \"\"\n",
    "\n",
    "        split_expression = re.findall(r\"(\\d*\\.?\\d+|[^0-9])\", filtered_expresseion)\n",
    "        for char in split_expression:\n",
    "            if char not in OPERATORS:\n",
    "                output += char\n",
    "            elif char == '(':\n",
    "                stack.append(char)\n",
    "            elif char == ')':\n",
    "                while stack != [] and stack[len(stack)-1] != '(':\n",
    "                    output += ' '\n",
    "                    output += stack.pop()\n",
    "                stack.pop()\n",
    "            else:\n",
    "                output += ' '\n",
    "                while stack != [] and stack[len(stack)-1] != '(' and PRIORITY[char] < PRIORITY[stack[len(stack)-1]]:\n",
    "                    output += stack.pop()\n",
    "\n",
    "                stack.append(char)\n",
    "\n",
    "        while stack != []:\n",
    "            output += ' '\n",
    "            output += stack.pop()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x=9 5 2 + +'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__infix_to_postfix(equation.replace(' ', \"\"), eq.replace(' ', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
